# Code Understanding Orchestrator Service

## Executive Summary

A standalone microservice that coordinates multiple specialized code understanding models (CodeT5+, GraphCodeBERT, CodeBERT) to dynamically extract, validate, and rank search terms from natural language queries. This service replaces hardcoded keyword mappings with intelligent, context-aware term generation.

This service acts as the **"Sous Chef"** in the Kitchen Brigade architectureâ€”interpreting orders (queries), preparing ingredients (keywords), curating results, and auditing output before serving to the customer.

---

## Kitchen Brigade Architecture Model

### The Analogy

The platform follows a **Kitchen Brigade** organizational model where each service has a specific role:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ğŸ½ï¸  KITCHEN BRIGADE MODEL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ‘¤ CUSTOMER (Claude/GPT/User)                                              â”‚
â”‚     â””â”€â†’ Places order: "I need code for document chunking with overlap"      â”‚
â”‚                                                                              â”‚
â”‚  ğŸ‘¨â€ğŸ³ SOUS CHEF (Code Understanding Orchestrator) â† THIS SERVICE             â”‚
â”‚     â””â”€â†’ SMART: Interprets the order                                         â”‚
â”‚     â””â”€â†’ Extracts keywords/concepts using code understanding models          â”‚
â”‚     â””â”€â†’ Sends keyword list to Cookbook                                      â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“– COOKBOOK (Semantic Search Service) â† DUMB RETRIEVAL                     â”‚
â”‚     â””â”€â†’ Takes keywords as INPUT (does NOT generate them)                    â”‚
â”‚     â””â”€â†’ Queries vector DBs (Qdrant, Neo4j) where content lives              â”‚
â”‚     â””â”€â†’ Returns ALL matches without filtering or judgment                   â”‚
â”‚     â””â”€â†’ Just a retrieval engine - like looking up recipes in a book         â”‚
â”‚                                                                              â”‚
â”‚  ğŸ‘¨â€ğŸ³ CHEF DE PARTIE (Orchestrator - Curation Phase)                         â”‚
â”‚     â””â”€â†’ Receives raw results from Cookbook                                  â”‚
â”‚     â””â”€â†’ SMART: Filters out irrelevant results (C++ "chunk of memory")       â”‚
â”‚     â””â”€â†’ Ranks by domain relevance                                           â”‚
â”‚     â””â”€â†’ Prepares curated instructions for Line Cook                         â”‚
â”‚                                                                              â”‚
â”‚  ğŸ‘¨â€ğŸ³ LINE COOK (Code Generation Model via LLM Gateway)                      â”‚
â”‚     â””â”€â†’ Receives curated context + instructions                             â”‚
â”‚     â””â”€â†’ Generates actual code from the instructions                         â”‚
â”‚                                                                              â”‚
â”‚  ğŸ‘¨â€ğŸ³ CHEF DE PARTIE (Orchestrator - Audit Phase)                            â”‚
â”‚     â””â”€â†’ Validates generated code quality                                    â”‚
â”‚     â””â”€â†’ Ensures code matches original intent                                â”‚
â”‚                                                                              â”‚
â”‚  ğŸ‘¤ CUSTOMER receives the final plated dish (working code)                  â”‚
â”‚     â””â”€â†’ Implements the code in their project                                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Responsibility Matrix

| Service | Role | Intelligence | What It Does | What It Does NOT Do |
|---------|------|--------------|--------------|---------------------|
| **LLM Gateway** | Router | Routing only | Routes requests to appropriate models | Make decisions about content |
| **Code Understanding Orchestrator** | Sous Chef + Chef de Partie | **SMART** | Extracts keywords, curates results, audits output | Store content, execute searches |
| **Semantic Search Service** | Cookbook | **DUMB** | Takes keywords as input, queries vector DBs, returns all matches | Generate keywords, filter results, make judgments |
| **Code Generation Model** | Line Cook | Executor | Generates code from curated instructions | Decide what to generate |
| **Vector DBs (Qdrant/Neo4j)** | Pantry | Storage | Stores embeddings and relationships | Nothing else |

### Key Insight: Semantic Search is DUMB

The **Semantic Search Service** is intentionally dumb:
- It does NOT contain knowledge itselfâ€”it queries databases that contain knowledge
- It does NOT generate keywordsâ€”it receives them as input
- It does NOT filter resultsâ€”it returns ALL matches
- It's just a query executor, like looking up recipes in a cookbook

The **intelligence lives in the Orchestrator**, which:
1. **Interprets** the customer's order (query understanding)
2. **Generates** the right keywords to search for
3. **Curates** the raw results (filters irrelevant matches)
4. **Instructs** the line cook (prepares context for code generation)
5. **Audits** the final output (validates generated code)

---

## Problem Statement

### Current State
The existing cross-reference system uses **hardcoded `FOCUS_SEARCH_TERMS`** mappings:

```python
FOCUS_SEARCH_TERMS = {
    "multi-stage chunking": [
        "chunk", "chunking", "split", "segment", ...  # Static, brittle
    ],
}
```

### Issues
1. **False Positives**: "chunk" matches C++ memory allocation ("chunk of memory") instead of LLM document chunking
2. **Not Portable**: Hardcoded terms don't transfer across taxonomies/domains
3. **Maintenance Burden**: Manual updates required for new concepts
4. **Limited Coverage**: Misses semantically related terms not in the list

### Proposed Solution
A multi-model orchestration service that dynamically generates contextually-relevant search terms.

---

## Architecture Overview

### High-Level System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ‘¤ CUSTOMER (Claude/GPT/User)                            â”‚
â”‚                "I need code for document chunking with overlap"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Request
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ‘¨â€ğŸ³ CODE UNDERSTANDING ORCHESTRATOR (Sous Chef)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                         API Gateway                                    â”‚  â”‚
â”‚  â”‚                    /extract, /validate, /search                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                  â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  Model Wrapper Orchestrator                            â”‚  â”‚
â”‚  â”‚                   (LangGraph State Machine)                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â”‚                       â”‚                       â”‚                       â”‚
â”‚      â–¼                       â–¼                       â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  CodeT5+    â”‚       â”‚GraphCodeBERTâ”‚       â”‚  CodeBERT   â”‚                â”‚
â”‚  â”‚  Extractor  â”‚       â”‚  Validator  â”‚       â”‚   Ranker    â”‚                â”‚
â”‚  â”‚ (Generator) â”‚       â”‚ (Validator) â”‚       â”‚  (Ranker)   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                              â”‚
â”‚  Output: ["chunking", "text_splitter", "overlap", "RAG", "embedding"]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Keywords (INPUT to Cookbook)
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸ“– SEMANTIC SEARCH SERVICE (Cookbook) - DUMB                  â”‚
â”‚                                                                              â”‚
â”‚  Input:  Keywords from Orchestrator                                          â”‚
â”‚  Action: Query vector databases                                              â”‚
â”‚  Output: ALL matches (no filtering, no judgment)                            â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Qdrant        â”‚  â”‚   Neo4j Graph   â”‚  â”‚   Hybrid        â”‚             â”‚
â”‚  â”‚   Retriever     â”‚  â”‚   Retriever     â”‚  â”‚   Search        â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚                    â”‚                    â”‚                        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                â”‚                                             â”‚
â”‚           Returns: [C++ memory chunk, LLM chunking, game chunks, ...]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Raw Results
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ‘¨â€ğŸ³ ORCHESTRATOR (Chef de Partie) - Curation Phase                 â”‚
â”‚                                                                              â”‚
â”‚  âœ“ Filter: Remove C++ "chunk of memory" (wrong domain)                      â”‚
â”‚  âœ“ Rank: Score by relevance to LLM/AI context                               â”‚
â”‚  âœ“ Prepare: Curated context for Line Cook                                   â”‚
â”‚                                                                              â”‚
â”‚  Output: Curated references + instructions for code generation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Curated Context
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ‘¨â€ğŸ³ LINE COOK (Code Generation Model)                     â”‚
â”‚                                                                              â”‚
â”‚  Input:  Curated context + generation instructions                          â”‚
â”‚  Action: Generate code based on best practices from references              â”‚
â”‚  Output: Working code implementation                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Generated Code
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ğŸ‘¨â€ğŸ³ ORCHESTRATOR (Chef de Partie) - Audit Phase                   â”‚
â”‚                                                                              â”‚
â”‚  âœ“ Validate: Code quality checks                                            â”‚
â”‚  âœ“ Verify: Matches original intent                                          â”‚
â”‚  âœ“ Format: Prepare final output                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ Final Result
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ‘¤ CUSTOMER receives final dish                      â”‚
â”‚                      (Working code ready to implement)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow: Where Content Actually Lives

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ—„ï¸  DATA LAYER (Pantry)                           â”‚
â”‚                                                                              â”‚
â”‚  These are the ACTUAL STORAGE systems - where content lives:                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  QDRANT (Vector Database)                                            â”‚   â”‚
â”‚  â”‚  â””â”€â†’ Stores: Document embeddings, chunk vectors                      â”‚   â”‚
â”‚  â”‚  â””â”€â†’ Contains: Textbook content, code patterns, technical docs       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  NEO4J (Graph Database)                                              â”‚   â”‚
â”‚  â”‚  â””â”€â†’ Stores: Relationships between concepts, cross-references        â”‚   â”‚
â”‚  â”‚  â””â”€â†’ Contains: Bookâ†’Chapterâ†’Sectionâ†’Concept relationships           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  JSON FILES (Local Textbooks)                                        â”‚   â”‚
â”‚  â”‚  â””â”€â†’ Stores: Raw textbook JSON files                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The Semantic Search Service QUERIES these systems - it doesn't contain them.
```

---

## Multi-Model Coordination Flow

### Model Wrapper Orchestration Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              User Query                                       â”‚
â”‚          "LLM code understanding with multi-stage chunking for RAG"          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ORCHESTRATOR STATE MACHINE                            â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STATE 1: EXTRACTION                                                     â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚ CodeT5+ Extractor                                                    â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Input:  "Extract technical search terms for: LLM code understanding  â”‚ â”‚ â”‚
â”‚  â”‚ â”‚          with multi-stage chunking for RAG"                          â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Output: {                                                             â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   "primary_terms": ["chunking", "RAG", "embedding", "LLM"],          â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   "related_terms": ["tokenization", "vector", "retrieval"],          â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   "code_patterns": ["text_splitter", "chunk_size", "overlap"]        â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ }                                                                     â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                          â”‚
â”‚                                    â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STATE 2: VALIDATION                                                      â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚ GraphCodeBERT Validator                                              â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Input:  Generated terms + Original query + Domain context            â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Validation Rules:                                                     â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   âœ“ "chunking" - Valid (LLM context, not memory allocation)          â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   âœ“ "RAG" - Valid (retrieval augmented generation)                   â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   âœ“ "embedding" - Valid (vector representations)                     â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   âœ— "split" - Rejected (too generic, high false positive rate)       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Expansions Added:                                                     â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   + "semantic_search" (related to RAG)                               â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   + "context_window" (related to chunking)                           â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   + "HNSW" (related to vector indexing)                              â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                          â”‚
â”‚                                    â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STATE 3: RANKING                                                         â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚ CodeBERT Ranker                                                      â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Input:  Validated terms + Original query embedding                   â”‚ â”‚ â”‚
â”‚  â”‚ â”‚                                                                       â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Similarity Scoring:                                                   â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   1. chunking         â†’ 0.95 (highest relevance)                     â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   2. RAG              â†’ 0.92                                         â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   3. embedding        â†’ 0.89                                         â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   4. context_window   â†’ 0.85                                         â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   5. semantic_search  â†’ 0.82                                         â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   6. tokenization     â†’ 0.78                                         â”‚ â”‚ â”‚
â”‚  â”‚ â”‚   7. vector           â†’ 0.75                                         â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                          â”‚
â”‚                                    â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STATE 4: CONSENSUS                                                       â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚ Agreement Filter: Terms must be approved by â‰¥2 models                    â”‚ â”‚
â”‚  â”‚                                                                           â”‚ â”‚
â”‚  â”‚ Final Output:                                                             â”‚ â”‚
â”‚  â”‚ {                                                                         â”‚ â”‚
â”‚  â”‚   "search_terms": [                                                       â”‚ â”‚
â”‚  â”‚     {"term": "chunking", "score": 0.95, "models_agreed": 3},             â”‚ â”‚
â”‚  â”‚     {"term": "RAG", "score": 0.92, "models_agreed": 3},                  â”‚ â”‚
â”‚  â”‚     {"term": "embedding", "score": 0.89, "models_agreed": 3},            â”‚ â”‚
â”‚  â”‚     {"term": "context_window", "score": 0.85, "models_agreed": 2},       â”‚ â”‚
â”‚  â”‚     {"term": "semantic_search", "score": 0.82, "models_agreed": 2}       â”‚ â”‚
â”‚  â”‚   ],                                                                      â”‚ â”‚
â”‚  â”‚   "excluded_terms": [                                                     â”‚ â”‚
â”‚  â”‚     {"term": "split", "reason": "Too generic", "models_agreed": 1}       â”‚ â”‚
â”‚  â”‚   ]                                                                       â”‚ â”‚
â”‚  â”‚ }                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Model Selection

### Keyword Extraction Pipeline (Sous Chef)

| Model | Role | Strength | HuggingFace ID |
|-------|------|----------|----------------|
| **CodeT5+** | Generator | Encoder-decoder architecture enables text generation; trained on NLâ†”Code pairs | `Salesforce/codet5p-220m` |
| **GraphCodeBERT** | Validator | Understands code structure via data flow graphs; catches semantic mismatches | `microsoft/graphcodebert-base` |
| **CodeBERT** | Ranker | Fast embeddings for similarity scoring; well-established baseline | `microsoft/codebert-base` |

### Code Generation (Line Cook)

| Model | Parameters | VRAM (BF16) | HumanEval | Notes |
|-------|------------|-------------|-----------|-------|
| **Qwen2.5-Coder-32B-Instruct** | 32B | ~64GB | 92.7% | Primary - Best open-source coding |
| **Qwen2.5-Coder-7B-Instruct** | 7.6B | ~16GB | ~73% | Fallback - Single GPU friendly |
| **DeepSeek Coder 33B-Instruct** | 33B | ~66GB | 79.3% | Alternative - Excellent multi-file reasoning |

### Model Comparison Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Capability     â”‚    CodeT5+     â”‚ GraphCodeBERT  â”‚    CodeBERT    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Text Generation    â”‚       âœ…       â”‚       âŒ       â”‚       âŒ       â”‚
â”‚ Code Structure     â”‚       âš ï¸       â”‚       âœ…       â”‚       âš ï¸       â”‚
â”‚ Embeddings         â”‚       âœ…       â”‚       âœ…       â”‚       âœ…       â”‚
â”‚ Zero-shot Ready    â”‚       âœ…       â”‚       âš ï¸       â”‚       âš ï¸       â”‚
â”‚ Parameters         â”‚    220M-6B     â”‚     125M       â”‚     125M       â”‚
â”‚ Inference Speed    â”‚    Medium      â”‚     Fast       â”‚     Fast       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend: âœ… Excellent  âš ï¸ Partial  âŒ Not supported
```

---

## Service API Design

### REST Endpoints

```yaml
openapi: 3.0.0
info:
  title: Code Understanding Orchestrator API
  version: 1.0.0

paths:
  /api/v1/extract:
    post:
      summary: Extract search terms from query
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                query:
                  type: string
                  example: "LLM code understanding with multi-stage chunking"
                domain:
                  type: string
                  example: "ai-ml"
                options:
                  type: object
                  properties:
                    min_confidence:
                      type: number
                      default: 0.7
                    max_terms:
                      type: integer
                      default: 10
                    require_consensus:
                      type: boolean
                      default: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ExtractionResult'

  /api/v1/validate:
    post:
      summary: Validate terms against domain context

  /api/v1/search:
    post:
      summary: Full pipeline - extract, validate, and search

  /api/v1/generate:
    post:
      summary: Generate code from curated context

components:
  schemas:
    ExtractionResult:
      type: object
      properties:
        search_terms:
          type: array
          items:
            type: object
            properties:
              term:
                type: string
              score:
                type: number
              models_agreed:
                type: integer
        excluded_terms:
          type: array
        metadata:
          type: object
          properties:
            processing_time_ms:
              type: integer
            models_used:
              type: array
```

---

## Use Cases

| Use Case | Description |
|----------|-------------|
| **Cross-Reference Enhancement** | Fix false positives like C++ "chunk of memory" vs LLM chunking |
| **Code Search** | Extract search terms from natural language queries about code |
| **Documentation Retrieval** | Find relevant docs based on technical questions |
| **API Discovery** | Match user intent to available API endpoints |
| **Codebase Q&A** | Power RAG systems for code understanding |
| **Code Review** | Identify related code patterns and best practices |

---

## Related Services

| Service | Repository | Role |
|---------|------------|------|
| **LLM Gateway** | `llm-gateway` | Routes requests to appropriate models |
| **Semantic Search Service** | `semantic-search-service` | Queries vector DBs (Cookbook) |
| **AI Agents** | `ai-agents` | Main orchestration layer |
| **LLM Document Enhancer** | `llm-document-enhancer` | Document processing pipeline |

---

## Next Steps

1. **Phase 1**: Basic FastAPI structure with health endpoints
2. **Phase 2**: Implement CodeT5+ Extractor (model wrapper)
3. **Phase 3**: Add GraphCodeBERT Validator (model wrapper)
4. **Phase 4**: Add CodeBERT Ranker (model wrapper)
5. **Phase 5**: Implement LangGraph orchestration
6. **Phase 6**: Add Line Cook (code generation) integration
7. **Phase 7**: Integration tests with semantic-search-service
8. **Phase 8**: Docker/Kubernetes deployment

---

## References

- [CodeT5+ Paper](https://arxiv.org/abs/2305.07922)
- [GraphCodeBERT Paper](https://arxiv.org/abs/2009.08366)
- [CodeBERT Paper](https://arxiv.org/abs/2002.08155)
- [Qwen2.5-Coder](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
